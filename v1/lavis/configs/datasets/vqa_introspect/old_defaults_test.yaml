 # Copyright (c) 2022, salesforce.com, inc.
 # All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

datasets:
  vqa_introspect_test: # name of the registry_name of dataset builder, in lavis/datasets/builders/caption_builder.py
    # data_dir: ${env.data_dir}/datasets
    data_type: images # [images|videos|features]

#    prompt_type: Reasoner   # ["Questioner_SingleSubQ", "Questioner_MultipleSubQ", "Answerer", "Reasoner"]

    build_info:
      # Be careful not to append minus sign (-) before split to avoid itemizing
      annotations:
        train:
          url:
              - VQA-Introspect/VQAIntrospect_trainv1.0.json
          storage:
              - VQA-Introspect/VQAIntrospect_trainv1.0.json
        val:
          url:
              - VQA-Introspect/VQAIntrospect_valv1.0.json
          storage:
              - VQA-Introspect/VQAIntrospect_valv1.0.json
#              - aokvqa/annotations/specialized_vocab_train_lavis.json
              # - aokvqa/annotations/large_vocab_train_lavis.json
        test:
          url:
              - VQA-Introspect/VQAIntrospect_valv1.0.json
          storage:
              - VQA-Introspect/VQAIntrospect_valv1.0.json
      images:
          storage: coco/images/





# # Copyright (c) 2022, salesforce.com, inc.
# # All rights reserved.
# # SPDX-License-Identifier: BSD-3-Clause
# # For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause
#
#datasets:
#  vqa_introspect_qar_caption: # name of the registry_name of dataset builder, in lavis/datasets/builders/caption_builder.py
#    # data_dir: ${env.data_dir}/datasets
#    data_type: images # [images|videos|features]
#
#    prompt_type: Reasoner   # ["Questioner_SingleSubQ", "Questioner_MultipleSubQ", "Answerer", "Reasoner"]
#
#    build_info:
#      # Be careful not to append minus sign (-) before split to avoid itemizing
#      annotations:
#        train:
#          url:
#            - VQAv2/v2_OpenEnded_mscoco_train2014_questions.json
#            - VQAv2/v2_mscoco_train2014_annotations.json
#            - VQA-Introspect/VQAIntrospect_trainv1.0.json
#          storage:
#            - VQAv2/v2_OpenEnded_mscoco_train2014_questions.json
#            - VQAv2/v2_mscoco_train2014_annotations.json
#            - VQA-Introspect/VQAIntrospect_trainv1.0.json
#        val:
#          url:
#            - VQAv2/v2_OpenEnded_mscoco_val2014_questions.json
#            - VQAv2/v2_mscoco_val2014_annotations.json
#            - VQA-Introspect/VQAIntrospect_valv1.0.json
#          storage:
#            - VQAv2/v2_OpenEnded_mscoco_val2014_questions.json
#            - VQAv2/v2_mscoco_val2014_annotations.json
#            - VQA-Introspect/VQAIntrospect_valv1.0.json
#      images:
#        storage: coco/images/
