

datasets:
  data_type: videos # [images|videos|features]
  n_frms: 4
  vqa_acc: False
  ann_paths:
    train:
      - TVQA/sevila_style/train.json
    val:
      - TVQA/sevila_style/val.json
      - TVQA/sub_questions_val.json
  
  vis_root: TVQA/frames_hq/

  vis_processor:
    train:
      name: "blip_video_eval"
      n_frms: 4
      image_size: 224
      min_scale: 0.9
      max_scale: 1.0
    eval:
      name: "blip_video_eval"
      n_frms: 4
      image_size: 224
      min_scale: 0.9
      max_scale: 1.0
  text_processor:
    train:
      name: "blip_question"
    eval:
      name: "blip_caption"
      
