

datasets:
  data_type: videos # [images|videos|features]
  n_frms: 4
  vqa_acc: False
  only_scene: False
  ann_paths:
    train:
      - AnotherMissOh/AnotherMissOhQA_train_set.json
      # - AnotherMissOh/sub_questions.json
      # - flipped_vqa/dramaqa/clipvitl14.pth
    val:
      - AnotherMissOh/AnotherMissOhQA_val_set.json
      - AnotherMissOh/sub_questions_val.json
      # - flipped_vqa/dramaqa/clipvitl14.pth
    # test:
    #  - AnotherMissOh/AnotherMissOhQA_test_set.json
  
  vis_root: AnotherMissOh/images/
  # vis_root: AnotherMissOh/AnotherMissOh_videos/total/
  # vis_features: flipped_vqa/dramaqa/clipvitl14.pth

  vis_processor:
    train:
      name: alpro_video_train
      n_frms: 5
      image_size: 224
      min_scale: 0.9
      max_scale: 1.0
    eval:
      name: alpro_video_eval
      n_frms: 5
      image_size: 224
      min_scale: 0.9
      max_scale: 1.0
  text_processor:
    train:
      name: "blip_question"
    eval:
      name: "blip_caption"
      